# Prometheus

## Install node_exporter

Инсталлируем с помощью ansible
../Projects/nginx_learning/ansible

```bash
ansible-playbook node_exporter.yaml --private-key /home/baggurd/.ssh/appuser_ed25519
```

В gcp нужно открыть порт 9100 делаем это через terraform
../Projects/nginx_learning/terraform

Проверка что все работает:
http://nginx.basov.world:9100/metrics

## Ключи запуска Node Exporter
Далее приведен список наиболее востребованных ключей Node Exporter
```
--log.level
Default: info
Данный ключ устанавливает уровень логирования. Возможные уровни логирования:
debug, info, warn, error.
```
```
--log.format
Defult: logfmt
Данный ключ устанавливает формат логов. Доступные форматы: logfmt и json.
```
```
--web.listen-address
Default: ":9100"
Данный ключ устанавливает адрес и порт, по которому будет доступен Node Exporter.
```
```
--web.telemetry-path
Default: "/metrics"
Данный ключ устанавливает адрес, по которому доступны результаты экспозиции.
```
```
--web.disable-exporter-metrics
Default: -
Данный ключ устанавливает список метрик, которые будут исключены из экспозиции.
Например, для исключения всех метрик, имя которых начинается с go_, значение ключа
будет: go_*. Допускается использовать перечисление нескольких метрик, с запятой в
качестве разделителя.
Полный список ключей можно просмотреть с помощью команды help.
node_exporter --help
```

## Install  blackbox_exporter
Инсталлируем с помощью ansible
../Projects/nginx_learning/ansible

```bash
ansible-playbook blackbox_exporter.yaml --private-key /home/baggurd/.ssh/appuser_ed25519
```

## ICMP протокол
добавили в blackbox.yml
```yaml
  icmp_slurm:
    prober: icmp
    timeout: 2s
    icmp:
      preferred_ip_protocol: "ip4"
```

Проверяем что prometheus.io доступен с помощью нашего модуля icmp_slurm
```bash
curl -is "http://localhost:9115/probe?module=icmp_slurm&target=prometheus.io" | grep probe_success
```
Результат должен быть таким:
```
# HELP probe_success Displays whether or not the probe was a success
# TYPE probe_success gauge
probe_success 1
```
или извне
```
http://nginx.basov.world:9115/probe?module=icmp_slurm&target=prometheus.io
```

### Полный список параметров для проверки по ICMP протоколу:
```
timeout
Default: scrape_timeout
Время, после которого проверка будет считаться неудачной. ​NB!​ Если значение не
задано, используется scrape_timeout, который передал Prometheus.
```
```
preferred_ip_protocolDefault: ip6
Какой протокол используется для проверки. Допустимые значения: ip4| ip6.
```
```
source_ip_address
Default: -
Если на сервере несколько IP адресов, можно указать, с какого ip будет проводиться
проверка.
```
```
dont_fragment
Default: false
Разрешен ли бит фрагментации пакетов. ​!NB ​Работает только с linux и IPv4.
```
```
payload_size
Default: -
Размер пакета, который отправляется при выполнении проверки.
```

## DNS протокол
В данной конфигурации будет проверяться, может ли DNS сервер разрешить имя prometheus.io
```yaml
  dns_slurm:
    prober: dns
    timeout: 2s
    dns:
      query_name: prometheus.io
      preferred_ip_protocol: ip4
```

В запросе, в качестве параметра module, передаётся имя проверки, а в качестве
параметра target – на какой DNS сервер будет отправлен запрос. С помощью grep
фильтруем результат, чтобы получить только результат проверки.
```bash
curl -is "http://localhost:9115/probe?module=dns_slurm&target=8.8.8.8" | grep probe_success
```

### Полный список параметров для проверки по dns протоколу:
```
timeoutDefault: scrape_timeout
Время, после которого проверка будет считаться неудачной. ​NB!​ Если значение не
задано, используется scrape_timeout, который передал Prometheus.
```
```
preferred_ip_protocol
Default: ip6
Какой протокол используется для проверки. Допустимые значения: ip4| ip6.
```
```
source_ip_address
Default: -
Если на сервере несколько IP адресов, можно указать, с какого ip будет проводиться
проверка.
```
```
transport_protocol
Default: udp
Протокол, по которому будет производиться проверка. Возможные значения: udp, tcp.
```
```
query_name​:
Default: -
Запрос, который будет отправлен на DNS сервер.
```
```
query_type
Default: "ANY"
Тип записи, который будет запрашиваться. По умолчанию, запрашиваются все типы
записей.
```

## TCP протокол
```yaml
  tcp_slurm:
    prober: tcp
    timeout: 2s
    tcp:
      query_response:
      - expect: "^SSH-2.0-"
      preferred_ip_protocol: "ip4"
```
В данной конфигурации будет проверяться, присутствует ли в ответе строка: SSH-2.0-
проверка
```bash
curl -is "http://localhost:9115/probe?module=tcp_slurm&target=127.0.0.1:22" | grep probe_success
```

### Полный список параметров для проверки по TCP протоколу:
```
timeout
Default: scrape_timeout
Время, после которого проверка будет считаться неудачной. ​NB!​ Если значение не
задано, используется scrape_timeout, который передал Prometheus.
```
```
preferred_ip_protocol
Default: ip6
Какой протокол используется для проверки. Допустимые значения: ip4| ip6.
```
```
query_response
* expect - проверка на наличие строки в ответе.
* send - позволяет задать, какой запрос будет отправлен на сервер.
* starttls - задает, будет ли использоваться tls при подключении, по умолчанию – false.
```
```
source_ip_address
Default: -
Если на сервере несколько IP адресов, можно указать, с какого ip будет проводиться
проверка.
```
```
tls
Default: false
Использовать ли tls после подключения.
```
```
tls_config
Настройки для tls. Возможны следующие ​настройки для tls​:
* insecure_skip_verify ​–​ ​проверять ли валидность сертификата. Значение по умолчанию – false.
* ca_file​ – путь к файлу с корневыми сертификатами.
* cert_file​ – путь к файлу с клиентским сертификатом.
* key_file ​– путь к файлу с клиентским ключом.
* server_name​ – строка для проверки имени сервера.
```

## HTTP протокол

В данной конфигурации для проверки используется протокол ip v4, проверяется версия
HTTP, код ответа, метод GET. Также проверка закончится с ошибкой, если не
используется https или если в ответе отсутствует слово: Prometheus.

```yaml
  http_slurm:
    prober: http
    timeout: 2s
    http:
      preferred_ip_protocol: "ip4"
      valid_http_versions: ["HTTP/1.1", "HTTP/2.0"]
      valid_status_codes: [200]
      fail_if_not_ssl: true
      method: GET
      fail_if_body_not_matches_regexp:
        - "Prometheus"
```
```bash
curl -is "http://localhost:9115/probe?module=http_slurm&target=http://prometheus.io" | grep probe_success
```
## Debug
```bash
curl -is "http://localhost:9115/probe?module=http_slurm&target=http://prometheus.io&debug=true"
```
## Полный список параметров для проверки по HTTP протоколу:
```
timeout
Default: scrape_timeout
Время, после которого проверка будет считаться неудачной. ​NB!​ Если значение не
задано, используется scrape_timeout, который передал Prometheus.
```
```
preferred_ip_protocol
Default: ip6
Какой протокол используется для проверки. Допустимые значения: ip4| ip6.
```
```
source_ip_address
Default: -
Если на сервере несколько IP адресов, можно указать, с какого ip будет проводиться
проверка.
```
```
valid_status_codes
default: 200
Проверка считается неудачной, если код не соответствует заданному.
```
```
valid_http_versions
Проверка считается неудачной, если версия HTTP не соответствует строке.
```
```
method
Default: GET
Тип запроса. Возможные значения: GET | POST.
```
```
headers
Список заголовков, которые передаются во время проверки.
```
```
no_follow_redirects
Default: false
Следовать ли редиректам при проверке.
```
```
fail_if_ssl
Deafult: false
Проверка считается неуспешной, если соединение установлено по https.
```
```
fail_if_body_matches_regexp
Проверка считается неуспешной, если в body присутствует строка удовлетворяющая
регулярному выражению.
```
```
fail_if_body_not_matches_regexp
Проверка считается неуспешной, если в body отсутствует строка удовлетворяющая
регулярному выражению.
```
```
fail_if_header_matches
Проверка считается неуспешной, если в ответе присутствует заголовок, значение
которого удовлетворяет регулярному выражению.
* header – имя заголовка, который проверяется.
* regexp – регулярное выражение, которое проверяется в значении заголовка.
* allow_missing – разрешить отсутствие заголовка. По умолчанию: false.
```
```
fail_if_header_not_matches
Проверка считается неуспешной, если в ответе отсутствует заголовок, значение которого
удовлетворяет регулярному выражению.
* header – имя заголовка, который проверяется.
* regexp – регулярное выражение, которое проверяется в значении заголовка.
* allow_missing – разрешить отсутствие заголовка. По умолчанию: false.
```
```
basic_auth
* username – имя пользователя, которое используется для авторизации на проверяемом сайте.
* password – пароль, который используется для авторизации на проверяемом сайте.
```
```
bearer_token
Токен для bearer авторизации.
```
```
bearer_token_file
Файл, который содержит токен для bearer авторизации.
```
```
proxy_url
Адрес proxy сервера, если проверку необходимо выполнить через proxy сервер.
```
```
body
Body, которое передается вместе с запросом.
```
```
tls_config
* insecure_skip_verify ​–​ ​проверять ли валидность сертификата. Значение по умолчанию: false
* ca_file​ – путь к файлу с корневыми сертификатами.
* cert_file​ – путь к файлу с клиентским сертификатом.
* key_file ​– путь к файлу с клиентским ключом.
* server_name​ – строка для проверки имени сервера.
```

## Default port allocations
Занятые порты которые лучше не использовать если пишем свой экспортер
https://github.com/prometheus/prometheus/wiki/Default-port-allocations


## Ключи запуска Prometheus

Далее приведен список наиболее востребованных ключей Prometheus:
```
--config.file
Default: "prometheus.yml"
Путь к конфигурационному файлу Prometheus. Если путь не полный, то поиск
производится по каталогу, из которого запущен Prometheus.
```
```
--web.listen-address
Default: "0.0.0.0:9090"
Адрес и порт, по которому доступны UI и метрики Prometheus.
```
```
--web.read-timeout
Default: 5m
Максимальное время ожидания ответа от сервера и закрытия idle подключений.
```
```
--storage.tsdb.path
Default: "data/"
Путь к каталогу для сохранения метрик.
```
```
--storage.tsdb.retention.time
Default: -
Как долго хранить данные метрик. Время хранения метрик, по умолчанию: 15 дней.
```
```
--storage.tsdb.retention.size
Default: 0B
[​Экспериментальная​] Максимальный размер, отведенный под хранение метрик.
Допускаются следующие единицы: KB, MB, GB, TB, PB. Первыми удаляются наиболее
старые данные.
```
```
--storage.remote.flush-deadlineDefault: 1m
Как долго ожидать окончания процесса сохранения данных при restart и reload.
```
```
--rules.alert.for-outage-tolerance
Default: 1h
Максимальное задержки для "for".
```
```
--rules.alert.for-grace-period
Default: 10m
Минимальное время восстановления состояния.
```
```
--rules.alert.resend-delay
Default: 1m
Минимальное время ожидания до отправки сообщения в Alertmanager.
```
```
--alertmanager.notification-queue-capacity
Default: 10000
Максимальное число сообщений, ожидающих отправки в Alertmanager.
```
```
--alertmanager.timeout
Default: 10s
Timeout для отправки сообщений в Alertmanager.
```
```
--query.timeout
Default: 2m
Максимальное время для выполнения запроса, после этого запрос будет сброшен.
```
```
--query.max-concurrency
Default: 20
Максимальное число параллельно выполняющихся запросов.
```
```
--log.levelDefault: info
Данный ключ устанавливает уровень логирования. Возможные уровни логирования:
debug, info, warn, error.
```
```
--log.format
Defult: logfmt
Данный ключ устанавливает формат логов. Доступные форматы: logfmt и json.
```
```
Полный список ключей можно просмотреть с помощью команды help:
prometheus --help
```

## PushGateway 
Сервис с которого prometheus собирает метрики которые могут сюда посылать по технологии push сервисы которые например не существуют долго. Например отработала какая-то задача и завершилась и отправила метрики на pushgateway а оттуда уже эти метрики забирает prometheus.

Pushgateway не очищает данные которые к нему приходят
### Ключи запуска PushGateway
Далее приведен список наиболее востребованных ключей Pushgateway:
```
--log.level
Default: info
Данный ключ устанавливает уровень логирования. Возможные уровни логирования:
debug, info, warn, error.
```
```
--log.format
Default: logfmt
Данный ключ устанавливает формат логов. Доступные форматы: logfmt и json.
```
```
--web.listen-address
Default: ":9091"
Данный ключ устанавливает адрес и порт, по которому будет доступен PushGateway.
```
```
--web.telemetry-path
Default: "/metrics"
```
```
--web.enable-admin-api
Default: -
Разрешить endpoints для администрирования. Это может потребоваться для очистки
данных pushgateway.
```
```
--persistence.file
Default: -
Файл для сохранения метрик. По умолчанию, значения метрик сохраняются только в
памяти.
```
```
--persistence.interval
Default: 5mМинимальное время, через которое данные будут сохранены в постоянный файл.
Полный список ключей можно просмотреть с помощью команды help:
pushgateway --help
```

### Структура URL

Имя задачи и labels передаются как часть URL. Все запросы начинаются с /metrics
```
/metrics/job/<JOB_NAME>{/<LABEL_NAME>/<LABEL_VALUE>}
```
```
<JOB_NAME> - используется как значение label job и является обязательным.
Далее идут пары <LABEL_NAME>/<LABEL_VALUE>, где
<LABEL_NAME> это имя label
<LABEL_VALUE> значение этого label
Их количество не ограничено.
```

Например, метрика:
```
slurm_pushgateway_test{job="test_job",instance="localhost", edu="slurm"}
```
будет преобразована в:
```
/metrics/job/test_job/instance/localhost/edu/slurm/
```
```
!!NB! ​Если label содержит "/", пробел или русские символы, то его необходимо
закодировать в base64. А при запросе указать @base64. Данная ключевое слово
помогает PushGateway понять, что контент закодирован.
```

Например, для передачи в качестве значения для label path, /var/tmp запрос будет выглядеть так
```
/metrics/job/test_job/path@base64/L3Zhci90bXA
```

### Метод PUT
Метод PUT в Pushgateway используется для отправки метрик на сервер Pushgateway

- PUT запрос замещает все метрики для группы. Код ответа может быть 200 – в случае успешного обновления, и 400 – в случае ошибки.
- Если запрос выполняется с пустым body, то это приводит к удалению всех метрик для группы. При этом push_times_seconds не обновляется.
- push_times_seconds – метка времени последнего удачного POST или PUT запроса.
- push_failure_time_seconds – метка времени последнего неудачного POST или PUT
запроса.

Пример использования метода PUT для отправки метрик на Pushgateway:
```
PUT /metrics/job/<job_name>/instance/<instance_label>
Content-Type: text/plain

# TYPE <metric_name> <metric_type>
<metric_name>{<label_name>=<label_value>} <metric_value>
```

Пример запроса с использованием cURL (отправляем метрику):
```
curl -XPUT -H "Content-Type: text/plain" --data-binary \
'# TYPE my_metric counter
my_metric{label1="value1", label2="value2"} 42' \
http://pushgateway.example.com/metrics/job/my_job/instance/my_instance
```
Обратите внимание, что в приведенном примере my_metric - это имя вашей метрики, label1 и label2 - это метки (label) для группировки метрик, 42 - значение метрики.

### Метод POST
Метод POST в Pushgateway используется для отправки группы метрик на сервер Pushgateway.

POST запрос работает аналогично PUT, но обновляет значение только для метрик,
которые присутствуют в запросе.
Если запрос выполняется с пустым body, то push_times_seconds обновляется, а
изменение ранее переданных метрик не производится.

```
POST /metrics/job/<job_name>/instance/<instance_label>
Content-Type: text/plain

# TYPE <metric_name_1> <metric_type>
<metric_name_1>{<label_name_1>=<label_value_1>} <metric_value_1>

# TYPE <metric_name_2> <metric_type>
<metric_name_2>{<label_name_2>=<label_value_2>} <metric_value_2>

...
```
Пример запроса с использованием cURL:
```
curl -XPOST -H "Content-Type: text/plain" --data-binary \
'# TYPE my_metric_1 counter
my_metric_1{label1="value1", label2="value2"} 42
# TYPE my_metric_2 gauge
my_metric_2{label1="value1", label2="value2"} 3.14' \
http://pushgateway.example.com/metrics/job/my_job/instance/my_instance
```

В этом примере мы отправляем две метрики: my_metric_1 с типом счетчика (counter) и my_metric_2 с типом метрики gauge. У каждой метрики есть метки (labels) label1 и label2 со значениями "value1" и "value2" соответственно.


Передаем метрики на pushgateway:
```
cat <<EOF | curl --data-binary @- http://127.0.0.1:9091/metrics/job/slurm_io_test_job/instance/nginx.basov.world
# TYPE slurm_io_edu_counter counter
slurm_io_edu_counter{type="counter"} 42
# TYPE slurm_io_gauge gauge
slurm_io_gauge 2398.283
EOF
```
Это метод POST. В команде curl, указанная операция --data-binary указывает, что данные должны быть отправлены в виде двоичных данных (без изменений), и именно этот метод используется по умолчанию при выполнении команды curl без указания явного метода

Метод POST используется для создания новых ресурсов или отправки данных на сервер. В данном случае, данные метрик отправляются на URL-адрес http://127.0.0.1:9091/metrics/job/slurm_io_test_job/instance/nginx.basov.world с помощью метода POST.

Когда используется метод POST, данные метрик передаются в теле запроса HTTP, что позволяет отправлять несколько метрик одновременно или отправлять более сложные данные, чем просто одна метрика.

Проверка что метрика отправилась
```bash
curl -L http://localhost:9091/metrics/ 
```

Ответ должен быть примерно таким:
```
push_failure_time_seconds{instance="monitoring.s00000.slurm.io",job="slurm_io_test_job"} 0
push_time_seconds{instance="monitoring.s00000.slurm.io",job="slurm_io_test_job"}
1.5736548226639028e+09
# TYPE slurm_io_edu_counter counter
slurm_io_edu_counter{instance="monitoring.s00000.slurm.io",job="slurm_io_test_job",type="co
unter"} 42
# TYPE slurm_io_gauge gauge
slurm_io_gauge{instance="monitoring.s00000.slurm.io",job="slurm_io_test_job"} 2398.283
```
```
push_failure_time_seconds равный 0. Это говорит о том, что еще не было неудачных отправок данных.
```
```
push_time_seconds, значение которой говорит о времени последней удачной отправки данных.
```
Также группировка произведена только по labels, которые передавались в URL. label type для slurm_io_edu_counter не учитывается.

В запросе был указан URL следующего вида: http://127.0.0.1:9091/metrics/job/slurm_io_test_job/instance/nginx.basov.world. Здесь slurm_io_test_job и nginx.basov.world являются метками (labels), по которым будет производиться группировка метрик.

Однако, фраза "label type для slurm_io_edu_counter не учитывается" указывает на то, что метка type для метрики slurm_io_edu_counter не будет использоваться для группировки метрик в Pushgateway. Это означает, что метрики с разными значениями type будут считаться как одна группа метрик, а не различные группы на основе значения этой метки.

Например, если бы вы отправили следующие метрики:
```
plaintext
Copy code
# TYPE slurm_io_edu_counter counter
slurm_io_edu_counter{type="counter", label1="value1"} 42
slurm_io_edu_counter{type="gauge", label1="value2"} 10
```
То обе метрики будут группироваться в одну группу slurm_io_edu_counter, игнорируя различие в значениях метки type. Это происходит потому, что метка type не была указана в URL-адресе запроса и, следовательно, не учитывается для группировки.

### UI PushGateway
http://nginx.basov.world:9091/
UI доступен по порту 9091. Интерфейс у него очень простой. В нем можно посмотреть
список групп, значение для метрик для каждой группы. Время последней удачной и
неудачной отправки данных. Можно также удалить группу.

### Метод DELETE
DELETE запрос используется для удаления метрик из PushGateway. Удаляется вся
группа метрик. Тело запроса всегда должно быть пустым.
При успешном выполнении код ответа всегда будет 202.

## Настройка Prometheus PushGateway
Настройка забора метрик (Scraping) c PushGateway


Как выполнить только определенный task в Ansible:
Выставляем tag на task и запускаем
```bash
ansible-playbook prometheus.yaml --private-key /home/baggurd/.ssh/appuser_ed25519 --tags "prometheus_config"
```
```prometheus.yml
  # Сбор метрик с pushgateway      
  - job_name: pushgateway
    honor_labels: true
    static_configs:
    - targets:
      - nginx.basov.world:9091
```

Заходим на prometheus http://nginx.basov.world:9090
Проверяем что метрики собрались:

```
slurm_io_edu_counter[1m]
```

# PromQL
В Prometheus есть 4 типа данных
* Counter - Может быть 0 или больше (не может принимать отрицательные значения)
* Gauge - может как уменьшаться так и увеличиваться (Например подходит для измерения свободной памяти на сервере)
* Histogram - Чаще используется для вычисления длительности запроса и размера ответа. Предоставляет информацию о количестве значений, попавших в определенные интервалы (бакеты), а также об общей сумме значений.
Histogramы в Prometheus обычно используются для измерения времени выполнения операций, количества запросов или других величин, которые могут быть разбиты на интервалы.

Для вычисления выражений с гистограммами в PROMQL доступны следующие функции:

    histogram_quantile: Вычисляет квантиль (процентиль) для гистограммы. Принимает два аргумента: значение квантиля и гистограмму.

    histogram_bucket: Возвращает количество наблюдений, попавших в указанный бакет гистограммы. Принимает два аргумента: значение бакета и гистограмму.

    histogram_sum: Возвращает общую сумму значений для гистограммы.

    histogram_count: Возвращает общее количество наблюдений (событий), попавших в гистограмму.

Пример использования выражений с гистограммами в PROMQL:
```
# Получить квантиль 90% для гистограммы с именем my_histogram
histogram_quantile(0.9, my_histogram)

# Получить количество наблюдений, попавших в бакет со значением 5.0 для гистограммы my_histogram
histogram_bucket(5.0, my_histogram)

# Получить общую сумму значений для гистограммы my_histogram
histogram_sum(my_histogram)

# Получить общее количество наблюдений (событий) для гистограммы my_histogram
histogram_count(my_histogram)
```
Гистограммы в PROMQL предоставляют полезную информацию о распределении данных, что позволяет более детально анализировать и мониторить различные метрики в системе.

- summary - расширенная Histogram
Summary в Prometheus подобен гистограмме, но предоставляет более легковесный способ оценки квантилей распределения. Он рассчитывает квантили "на лету" постепенно, основываясь на зарегистрированных образцах, и не требует хранения всех значений метрик, как в случае с гистограммой.

Для вычисления выражений с сводкой в PROMQL доступны следующие функции:

    quantile: Вычисляет квантиль (процентиль) для сводки. Принимает два аргумента: значение квантиля и сводку.

    avg: Возвращает среднее значение для сводки.

    sum: Возвращает общую сумму значений для сводки.

    count: Возвращает общее количество образцов (событий) для сводки.

Пример использования выражений с сводкой в PROMQL:
```
# Получить квантиль 90% для сводки с именем my_summary
quantile(0.9, my_summary)

# Получить среднее значение для сводки my_summary
avg(my_summary)

# Получить общую сумму значений для сводки my_summary
sum(my_summary)

# Получить общее количество образцов (событий) для сводки my_summary
count(my_summary)
```
Отличие между гистограммой и сводкой заключается в том, что гистограмма разбивает данные на бакеты с фиксированными интервалами и предоставляет информацию о количестве значений в каждом бакете, в то время как сводка основывается на квантилях и общем количестве образцов. Гистограмма более подходит для анализа распределения данных с детализацией по интервалам, тогда как сводка хорошо работает для получения квантилей и общих статистических показателей. Выбор между использованием гистограммы или сводки зависит от требуемых целей мониторинга и анализа.

## Типы данных в PromQL
В запросах Prometheus есть 3 типа данных:
- Instant vector​ – вектор содержит в себе все значения метрики по запрашиваемой метке времени.
- Range vectors​ – возвращает все вектора за указанный период времени. Это позволяет увидеть изменение метрики во времени.
- Scalar​ ​–​ простое числовое значение с плавающей точкой.

### Математические операторы
```
Сложение (+): Складывает значения метрик или скалярные значения. Например: metric1 + metric2 или scalar1 + scalar2.

Вычитание (-): Вычитает значения метрик или скалярные значения. Например: metric1 - metric2 или scalar1 - scalar2.

Умножение (*): Умножает значения метрик или скалярные значения. Например: metric1 * metric2 или scalar1 * scalar2.

Деление (/): Делит значения метрик или скалярные значения. Например: metric1 / metric2 или scalar1 / scalar2.

Возведение в степень (^): Возводит значения метрик или скалярные значения в указанную степень. Например: metric1 ^ metric2 или scalar1 ^ scalar2.

Остаток от деления (%): Возвращает остаток от деления значений метрик или скалярных значений. Например: metric1 % metric2 или scalar1 % scalar2.

Негация (-): Изменяет знак значения метрики или скалярного значения на противоположный. Например: -metric1 или -scalar1.

Скобки (): Используются для управления порядком выполнения операций. Выражения в скобках будут вычисляться в первую очередь.
```

### Операторы сравнения:
```
== – равно
!= – не равно
> – больше
< – меньше
>= – больше или равно
<= – меньше или равно
```

Сравнение возможно только над scalar и instant vector. Оператор применяется к каждому значению в исходном векторе, и все элементы данных, для которых не выполняется  условие сравнения, исключаются из результирующего вектора.
Если указан модификатор bool, то в результирующем векторе данные, которые
удовлетворяют условию сравнения, будут иметь значение 1, а не удовлетворяющие 0.

NB! ​Сравнение двух scalar возможно только с модификатором bool.

### Логические операторы:
```
and – логическое И
or – логическое ИЛИ
unless – дополнение
```
Логические операторы возможны только между instant vector.

Пример использования оператора and:
Предположим, у нас есть метрика http_requests_total, которая показывает общее количество HTTP-запросов, и мы хотим найти метрики, где количество запросов больше 1000 и код ответа равен 200.

```
http_requests_total{status_code="200"} > 1000 and http_requests_total > 1000
```
Этот запрос вернет метрики http_requests_total, где общее количество запросов больше 1000 и код ответа равен 200.

Пример использования оператора or:
Предположим, у нас есть метрика cpu_usage, которая показывает процент использования CPU, и мы хотим найти метрики, где процент использования CPU больше 90% или процент использования памяти больше 80%.

```
cpu_usage > 90 or memory_usage > 80
```
Этот запрос вернет метрики, где либо процент использования CPU больше 90%, либо процент использования памяти больше 80%.

Пример использования оператора unless:
Предположим, у нас есть метрика http_requests_total, которая показывает общее количество HTTP-запросов, и мы хотим найти метрики, где количество запросов не превышает 1000.
```
unless http_requests_total > 1000
```
Этот запрос вернет метрики http_requests_total, где общее количество запросов не превышает 1000.


## Сумарное потребление cpu по двум серверам

```
node_cpu_seconds_total{instance="nginx.basov.world:9100",job="static_config"}+on(cpu, mode) node_cpu_seconds_total{instance="vasiliy.basov.world:9100",job="static_config"}
```

Существует 2 модификатора для сравнения:
- on – задает, какие labels необходимо учитывать при сопоставлении.
- ignoring – задает, какие labels должны быть исключены в процессе
сопоставления.

## Операторы агрегации:
- sum – сумма
- min – минимальное значение
- max – максимальное значение
- avg – среднее значение
- stddev – стандартное отклонение
- stdvar – стандартная дисперсия
- count – количество элементов в векторе
- count_values – количество элементов с одинаковым значением.

Данные операторы могут использоваться с модификаторами ​by​ и ​without​. C помощью модификатора by задается список labels, которые будут учитываться, а модификатор without задает список labels, которые учитываться не будут. Указание данного модификатора допускается как до, так и после запроса.
```
operator ([parameter,] <vector expression>) [without|by (<label list>)]
```

Например, чтобы получить суммарное потребление cpu по всем инстансам в user mode,
выполните следующий запрос:
```
sum(node_cpu_seconds_total{mode="user"}) by (cpu)
```

Чтобы получить суммарное потребление процессора в user mode по всем ядрам,
выполните запрос:

```
sum without (cpu) (node_cpu_seconds_total{mode="user"})
```

## Приоритет бинарных операторов
Бинарные операторы имеют следующий приоритет:
1. ^
2. * , / , %
3. + , -
4. == != , <= , < , >= , >
5. and , unless
6. or

## Математические функции
```
abs
Функция возвращает абсолютные значения, то есть любые отрицательные значения
заменяются положительными. abs(vector(-10)) вернет: 10
```
```
ln, log2, and log10
Набор данных функций принимают мгновенный вектор и возвращают логарифм значений,
используя разные основания.
```
```
exp
Функция возвращает экспоненту для моментального вектора. Эта функция является
обратной для ln.
```
```
sqrt
Функция возвращает результат возведения в квадратный корень. Она эквивалентна
математическому выражению ^ 0.5.
```
```
ceil​ ​and floor
Функция округления значений вектора.
ceil – округляет в большую сторону: ceil(vector(1.1)) вернет 2.
floor – округляет в меньшую сторону: floor(vector(1.1)) вернет 1.
```
```
round
Функция возвращает результат округления. Округление производится до ближайшего
целого числа.
round (vector(1.1)) вернет: 1, round (vector(1.6)) вернет: 2.
Если значение находится ровно посередине между двумя целыми числами, округление
производится в большую сторону.
round (vector(1.5)) вернет: 2.Для функции round может быть задан дополнительный аргумент. В этом случае функция
вернет ближайшее целое число кратное, заданному аргументу. round(vector(17), 5)
вернет: 15
```
```
clamp_max and clamp_min
Функция clamp_max – заменяет все значения выше заданного на максимальное.
clamp_max(vector(9), 5) вернет: 5.
Функция clamp_min – заменяет все значения меньше заданного на минимальное.
clamp_min(vector(3), 5) вернет: 5.
```

## Функции времени и даты
```
time
Функция возвращает текущее время в Unix time формате.
```
```
minute, hour, day_of_week, day_of_month, days_in_month, month, and
year
Данные функции возвращают:
minute - минуты
hour - часы
day_of_week - день недели
day_of_month - день месяца
days_in_month - количество дней в месяце
month - месяц
year - год
В качестве аргументов эти функции могут принимать вектор, значение которого – дата.
Например, year(process_start_time_seconds) вернет год, в котором был запущен процесс.
```
```
timestamp
Это функция, в отличие от остальных функций времени, смотрит не на значение вектора,
а на его временную метку и возвращает ее значение.
```

## Метки
```
label_replace
Функция позволяет добавить новую метку на основании уже имеющихся. Это удобно,
когда вы агрегируете данные из разных источников, где метки имеют одинаковый смысл,
а их названия различаются. Например, запрос label_replace(up, "replace", "${1}", "job",
"(.*)") вернет: up{instance="localhost:9090",job="prometheus",replace="prometheus"}
```
```
label_join
Позволяет объединять значения нескольких меток в одну. Например, запрос label_join(up,
"join", "-", "job", "instance") вернет:
up{instance="localhost:9090",job="prometheus",join="prometheus-localhost:9090"}
```
Важно!​ label_join и label_replace не удаляют имена метрик.

## Пропущенные серии
```
absent
Функция возвращает пустой вектор, если переданный ей вектор содержит значения. В
противном случае она возвращает 1.
```

## Сортировки
```
sort
Функция позволяет отсортировать значения в возвращаемом векторе. Сортировка
производится по возрастанию.
```
```
sort_desc
Функция позволяет отсортировать значения в возвращаемом векторе. Сортировка
производится по убыванию
```
## Агрегация во времени

<aggregation>_over_time()
Следующие функции позволяют агрегировать каждую серию заданного диапазона
вектора во времени и возвращать мгновенный вектор с результатами агрегации для
каждой серии:
```
avg_over_time
Функция возвращает среднее значение всех точек в указанном интервале.
```
```
min_over_time
Функция возвращает минимальное значение всех точек в указанном интервале.
```
```
max_over_time
Функция возвращает максимальное значение всех точек в указанном интервале.
```
```
sum_over_time
Функция возвращает сумму всех значений в указанном интервале.
```
```
count_over_time
Функция возвращает количество всех значений в указанном интервале.
```
```
quantile_over_time
Функция возвращает φ-квантиль (0 ≤ φ ≤ 1) значений в указанном интервале.
```
```
stddev_over_time
Функция возвращает стандартное отклонение совокупности значений в указанном
интервале.
```
```
stdvar_over_time
Функция возвращает стандартную дисперсию совокупности значений в указанном
интервале.
```


## Функции для сounter
```
topk и bottomk
Функция вычисляет среднюю скорость увеличения временного ряда в секунду. При
сбросе счетчика в 0, данные корректируются, чтобы это не влияло на конечный результат.
NB! ​topk и bottomk при использовании с by и without, в отличие от остальных операторов
агрегации, возвращают полный набор метрик, а by и without используется только для группировки значений.
```
```
increase
Функция вычисляет увеличение во временном ряду в диапазоне вектора. Формула для
расчета: rate(x_total [time]) * time
```
```
irate
Функция вычисляет мгновенную скорость увеличения временного ряда в векторе
диапазона. Он похож на rate, но для анализа использует последние две выборки вектора.
```
```
resets
Функция вычисляет число сбросов счетчика в предоставленном временном диапазоне в
качестве мгновенного вектора. Любое уменьшение значения между двумя
последовательными выборками интерпретируется как сброс счетчика.
```
## Функции для Histograms

```
histogram_quantile
Функция группирует значения по bucket, а затем вычисляет φ-квантиль (0 ≤ φ ≤ 1).
Функция rate() позволяет произвести расчет за период времени. Функция:
histogram_quantile(0.90,rate(prometheus_tsdb_compaction_duration_seconds_bucket[1d]))
рассчитывает 0,9 квантиль для prometheus_tsdb_compaction_duration_seconds_bucket за
предыдущий день.
Значения за пределами 0 ≤ φ ≤ 1 не имеют смысла и равняются бесконечности.
Предпочтительным способом расчета квантили является использование​ ​Summary, но
некоторые exporters предоставляют данные в виде Histogram. В этом случае
использование функции​ ​histogram_quantile является обоснованным.
```
## Функции для Gauges
```
changes
Функция позволяет подсчитать, сколько раз временной ряд изменил свое значение.
Данная функция удобна, например, для подсчета количества перезапусков процесса за период времени.
```
```
deriv
Функция позволяет узнать скорость изменения временного ряда в секунду за период
времени. Эта функция похожа на x - x offset 1h, но на результат данного запроса могут
повлиять локальные выбросы, а deriv для расчета значения использует функцию простой
линейной регрессии, что делает ее результат точнее и устойчивее к локальным
выбросам.
```
```
predict_linear
Функция возвращает предсказание о значении временного ряда через n секунд.
Предсказание вычисляется с помощью функции простой линейной регрессии.
```
```
delta
Функция похожа на increase и возвращает изменение временного ряда за период
времени, но без учета сбросов. Данная функция является чувствительной к локальным
выбросам и использовать ее стоит с осторожностью.
```
```
idelta
Функция возвращает разницу между последними 2-мя значениями во временном ряду.
```
```
holt_winters
Функция реализует двойное экспоненциальное сглаживание Holt-Winters. Это полезно для
очистки данных от локальных выбросов и оценки трендов изменения метрики. В качестве
входных параметров функция принимает временной ряд, коэффициент сглаживания и
коэффициент важности более старых данных по отношению к более новым.
```
## Record Rules
Можем сохранять результаты запроса в новый временной ряд
## Настройка Rules

Rules описываются в отдельном конфигурационном файле. Формат - yml. Prometheus
поддерживает загрузку правил из нескольких файлов. Rules загружаются только при
отсутствии ошибок во всех Rules. Для проверки на наличие синтаксических ошибок можно
использовать утилиту promtool.
```
promtool check rules /path/to/example.rules.yml
```
NB!​ На файлы с правилами не выставляется inotify, поэтому после любого изменения правил требуется, как минимум, выполнять reload – для того, чтобы Prometheus применил изменения.


Чтобы загрузить правила в Prometheus, список файлов с Rules необходимо взять в
основном конфигурационном файле Prometheus.
```
rule_files:
  - "rules_file1.yml"
  - "rules_file2.yml"
  - "rules/*.yml"
```

## Синтаксис rules файла
```yaml
groups:
  # это имя для группы правил
  - name: example
    # интервал, с которым будет производиться выполнение и сохранение правил в группе
    interval: 10s
    rules:
    # имя, по которому результат будет доступен при извлечении данных.
    - record: job:process_cpu_seconds:rate5m
      # выражение, которое используется для вычисления. Является обязательным.
      expr: sum without(instance)(rate(process_cpu_seconds_total[5m]))
      # список меток, которые будут добавлены к вектору. Не является обязательным.
      labels:
        slurm_edu: exmple_rules
```

## Именование Rules

Для Rules у Prometheus имеются рекомендации по именованию правил, что упрощает
интерпретацию значения правила.
1. Разделителем в имени правила является ":"
2. Общий вид имени должен быть таким:
level:metric:operations

- level ​–​ ​отражает уровень агрегации на основании labels. Он должен включать метку job и
другие значимые labels, которые имеют отношение к метрике.
- metric ​–​ ​это имя метрики. Допускается удаление _total, но в остальных случаях это
должно быть точное название исходной метрики. Для обозначения необходимо
использовать _per_.
- operations ​– представляет собой список функций и агрегаций, примененных к метрике.
Если применяется несколько одинаковых функций, например min, указывать необходимо
только одну.

Для лучшего понимания ниже приведено несколько примеров:

```
- record: instance_path:request_latency_seconds_count:rate5m
expr: rate(request_latency_seconds_count{job="myjob"}[5m])
```
```
- record: instance_path:request_latency_seconds_sum:rate5m
expr: rate(request_latency_seconds_sum{job="myjob"}[5m])
```
```
- record: job:request_failures_per_requests:ratio_rate5m
  expr: |2
    sum without (instance, path)(instance_path:request_failures:rate5m{job="myjob"}) / sum without (instance, path)(instance_path:requests:rate5m{job="myjob"})
```

## Настройка Alert Rules
Настраиваем ../nginx_learning/ansible/roles/prometheus/templates/rules_alert.yml
```
/etc/prometheus/rules_alert.yml
```
Добавляем данные о Rules в основной конфигурационый файл Prometheus.yml
```yaml
rule_files:
  - {{ prometheus_config_dir }}/rules.yml
  - {{ prometheus_config_dir }}/rules_alert.yml
```
Проверяем, что правила появились.
http://nginx.basov.world:9090/alerts

### Тестирование работы правил

Отключаем node_exporter, выполнив команду:
```bash
systemctl stop node_exporter.service
```
Возвращаемся на страницу: http://<адрес сервера monitoring>:9090/alerts. 
Одно из alert rule должно перейти в состояние PENDING
По истечению времени, указанного в for(5m), alert rule перейдет в состояние: FIRING

NB! ​Обратите внимание: Prom сам не обновляет страницы. Чтобы увидеть добавленные
данные, необходимо обновить страницу (нажать F5).
NB! ​Установленная галочка: "Show annotations" позволяет просмотреть Annotations labels
c уже подставленными в шаблон значениями.

## Настройка Alertmanager

ansible-playbook alertmanager.yaml --private-key /home/baggurd/.ssh/appuser_ed25519

Добавление в prometheus.yml
```yaml
# Alertmanager configuration
# Настройка для взаимодействия с Alert Manager.
alerting:
  # alert_relabel_configs:
  #   [ - <relabel_config> ... ]
  alertmanagers:
    - static_configs:
        - targets:
          - 'localhost:9093'
```

### Ключи запуска Alertmanager
Далее приведен список наиболее востребованных ключей Alertmanager:
```
--config.file
Default: alertmanager.yml
Имя конфигурационного файла.
```
```
--storage.path
Default: data/
Путь, куда сохраняются данные.
```
```
--data.retention
Default: 120h
Как долго хранить данные.
```
```
--web.listen-address
Default: ":9093"
Адрес и порт, по которому доступны UI и метрики Alertmanager.
```
```
--cluster.listen-address
Default: "0.0.0.0:9094"
Адрес для HA кластера. Пустое значение для отключения HA mode.
```
```
--cluster.advertise-address
Default: -
IP для анонса в кластере.
```
```
--cluster.peer
Defalut: -
Адреса peer в HA кластере.
```
```
--log.level
Default: info
Данный ключ устанавливает уровень логирования. Возможные уровни логирования:
debug, info, warn, error.
```
```
--log.format
Default: logfmt
Данный ключ устанавливает формат логов. Доступные форматы: logfmt и json.
```
```
Полный список ключей можно просмотреть с помощью команды help:
alertmanager --help
```

## Настройка Alertmanager

alertmanager.yml:

### Блок global
```
resolve_timeout
default: 5m Время, через которое алерт считается решенным, если в течение этого
времени он не был обновлен.
```
```
smtp_from​ default: – email адрес, который будет использован в качестве адреса
отправителя. В блоке global объявляются значения по умолчанию, переопределить
которые можно в блоке receiver.
```
```
smtp_smarthost
default:
Адрес SMTP сервера, который используется для отправки. Формат: ip:port . В блоке global объявляются значения по умолчанию, переопределить которые можно в блоке receiver.
```
```
smtp_require_tls
default: true
Задает, использовать ли tls при подключении к SMTP. ​NB!​ Обратите внимание, что
значение по умолчанию true и при использовании с локально установленным postfix без дополнительных настроек работать не будет.
Также в этой секции возможно настроить отправку уведомлений в: slack, hipchat,
pagerduty и другие мессенджеры. Но для настройки получателей рекомендуется
использовать webhook. Его настройка возможна только в разделе receivers.
```


### Блок route

В блоке route производится маршрутизация сообщений. В результате получается
древовидная структура.
```
receiver
Имя конфигурации, которая будет использована для отправки уведомлений.
```
```
group_by
Набор меток, по которым производится агрегация. Значение ['...'] отключает группировку.
```
```
сontinue
default: false
Если значение false, обработка уведомления прекращается при первом совпадении. Если значение true, обработка продолжается и выбирается последний route, удовлетворяющий условиям.
```
```
match
Список меток key: value, при точном совпадении с которыми выбирается этот маршрут.
```
```
match_re
Список меток key: regex, при совпадении с которыми выбирается этот маршрут.
```
```
group_wait
Default: 30s
Время задержки перед отправкой сообщений для группы. Позволяет дождаться
поступления большего числа алертов и произвести эффективную группировку.
```
```
group_interval
default: 5m
Время задержки для отправки новых уведомлений, по которым первоначальное
уведомление уже было отправлено.
```
```
repeat_interval
default: 4h
Время задержки для повторной отправки уведомления.
```

routes
Дополнительные маршруты. Не являются обязательными.
Пример:

```yaml
route:
  receiver: 'default-receiver'
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 4h
  group_by: [cluster, alertname]
  routes:
  - receiver: 'db-team'
    group_wait: 10s
    match_re:
      service: mysql|postgres
  - receiver: 'frontend-team'
  group_by: [product, environment]
  match:
    team: frontend
```
В этом примере все уведомления labels service со значениями mysql или postgres будут отправлены db-team. Уведомления, имеющие label team со значением frontend, будут отправлены frontend-team. Остальные уведомления будут отправлены получателю по-умолчанию.

### Блок receivers
Receiver – это именованная конфигурация одного или нескольких получателей
уведомлений. На данный момент имеется интеграция с несколькими мессенджерами:
slack, hipchat, pagerduty и др. Но для настройки получателей рекомендуется использовать webhook. В настройках указываются данные для отправки. Пример настройки email будет рассмотрен в следующем шаге.

### Блок inhibit_rules
Блок inhibit_rules позволяет отключить уведомления для алертов, у которых labels
соответствуют набору labels, указанных в target_match(_re), и при условии, что уже есть уведомление, у которого набор labels соответствуют набору labels, указанных в source_match(_re).
```
target_match
Список labels, при совпадении с которым сообщение будет отключено.
```
```
target_match_re
Список labels, при совпадении с которым сообщение будет отключено. Для проверки
используется регулярное выражение.
```
```
source_match
Набор меток, для которых уже должен существовать алерт, чтобы правило подавления
работало.
```
```
source_match_re
Набор меток, для которых уже должен существовать алерт, чтобы правило подавления
работало. Для проверки используется регулярное выражение.
```
```
equal
Набор label, которые должны совпадать в alert и inhibit alert, чтобы подавление работало.
```
### Блок templates
В данном блоке задается список путей для файлов с пользовательскими шаблонами
уведомлений. Допускается использование маски.
Пример:
```
templates:
- 'templates/*.tmpl'
```

NB!​ В реальной жизни routing будет намного сложнее, и для его визуализации можно
воспользоваться​ ​сайтом​. https://prometheus.io/webtools/alerting/routing-tree-editor/


### Настройка alertmanager практика

```yaml
# Чтобы эта настройка сработала нужно настроить пароль для приложений в настройках безопасности yandex
# также нужно поставть Разрешить доступ к почтовому ящику с помощью почтовых клиентов С сервера imap.yandex.ru по протоколу IMAP
global:
  smtp_smarthost: smtp.yandex.ru:465
  smtp_from: 'baggurdprom@yandex.ru'
  smtp_auth_username: 'baggurdprom@yandex.ru'
  smtp_auth_password: 'сложныйпароль'

route:
  # объединяем связанные уведомления в одну группу. Уведомления будут группироваться по значениям меток alertname (имя алерта) и service (сервис)
  group_by: ['alertname', 'service']
  # Время ожидания (в секундах) для формирования группы уведомлений
  group_wait: 30s
  # параметр определяет интервал (в минутах) между отправкой групп уведомлений
  group_interval: 5m
  # параметр определяет интервал (в часах) повторной отправки уведомлений, если состояние алерта не изменяется
  repeat_interval: 1h
  # Этот параметр указывает, какой получатель (receiver) будет использоваться для отправки уведомлений
  receiver: team-monitoring

  # Это правило указывает, что уведомления, которые имеют метку service со значением "prom", должны быть отправлены на получателя (receiver) с именем team-ops 
  routes:
  - receiver: 'team-ops'
    matchers:
    - service="prom"
  # Это правило указывает, что уведомления, которые имеют метку severity со значением "warnings", "error" или "critical", должны быть отправлены на получателя (receiver) с именем team-monitoring
  - receiver: 'team-monitoring'
    matchers:
    - severity=~"warnings|error|critical"

receivers:
- name: 'team-ops'
  email_configs:
  - to: 'baggurd@mail.ru'
    send_resolved: true
    require_tls: false
- name: 'team-monitoring'
  email_configs:
  - to: 'dramikon@mail.ru'
    send_resolved: true 

# Подавление уведомлений
inhibit_rules:
  # Это правило подавления будет применяться, когда уведомление имеет источник (source) с метками severity: 'critical' и alertname: PrometheusConfigurationReload, 
  # и при этом существует цель (target) с меткой severity: 'error'. В таком случае, уведомление, соответствующее этим условиям, не будет отправлено, и оно будет подавлено.
  - source_match:
      severity: 'critical'
      alertname: PrometheusConfigurationReload
    target_match:
      severity: 'error'

```
```bash
ansible-playbook alertmanager.yaml --private-key /home/baggurd/.ssh/appuser_ed25519 --tags "alertmanager_config"
```

## Настройка Grafana

```bash
ansible-playbook grafana.yaml --private-key /home/baggurd/.ssh/appuser_ed25519
```
Имя пользователя и пароль по умолчанию admin/admin
Добавляем Prometheus в качестве источника данных.
выбираем Add data source:
```
Name​ – имя data source, должно быть уникальным.
```
```
URL​ – адрес, где располагается prometheus. Так как grafana установлена на том же
сервере, что и Prom, указываем: http://localhost:9090
```
```
Access​ – способ подключения к Prometheus. Server – запрос из браузера отправляется в
grafana, grafana производит подключения к Prometheus. Browser – в этом случае запросы
в Prometheus отправляются напрямую из браузера. Метод Browser менее
предпочтителен, так как приводит к необходимости открывать прямой доступ к
Prometheus.
```
```
Auth ​– задаются учетные данные для подключения к Prom.
```
```
Scrape interval ​– рекомендуется выставить равным глобальному значению scrape,
установленному в Prometheus.
```
```
Query timeout​ – задает максимальное время выполнения запроса к Prometheus.
```
```
HTTP Method​ – метод для отправки запросов в Prom. Post запросы возможны, начиная с
версии: 2.1.0
```
Сохраняем изменения.

Настройка dashboard в Grafana
см слайды

Импорт дашбоардов
https://grafana.com/grafana/dashboards/11074

## Настройка Prometheus в режиме HA
Необходимо установить Prometheus на серверы ​server1 и server2
После установки на каждом из Prometheus серверов необходимо заменить конфигурационный файл

### Настройка HA Proxy
Для доступа из Grafana к Prom необходимо установить HAProxy, для повышения отказоустойчивости
Устанавливаем HAProxy:
```bash
ansible-playbook haproxy.yaml --private-key /home/baggurd/.ssh/appuser_ed25519 --limit prom
```
Настраиваем /etc/haproxy/haproxy.cfg

```conf
global
  # Этот параметр указывает HAProxy работать в фоновом режиме как демон
  daemon
  # максимальное количество одновременных подключений к HAProxy
  maxconn 256
# настройки по умолчанию для всех прокси и frontend секций  
defaults
  # HAProxy будет работать как балансировщик для HTTP трафика
  mode http
  # Этот параметр определяет тайм-аут соединения с бэкенд-сервером
  timeout connect 5000ms
  # Этот параметр определяет тайм-аут ожидания клиента. Если клиент не отправит запрос в течение 50000 миллисекунд, то HAProxy закроет соединение.
  timeout client 50000ms
  # Этот параметр определяет тайм-аут ожидания сервера. Если бэкенд-сервер не ответит на запрос в течение 50000 миллисекунд, то HAProxy закроет соединение.
  timeout server 50000ms
# Раздел для ститистики и мониторинга HAProxy  
listen stats
  # Этот параметр указывает на прослушивание всех доступных IP-адресов на порту 9999
  bind *:9999
  # Включение статистики HAProxy.
  stats enable
  # Скрытие версии HAProxy из вывода статистики.
  stats hide-version
  # URI, по которому будет доступна статистика HAProxy.
  stats uri /stats
  # Параметр для аутентификации при доступе к статистике. В данном случае, логин и пароль для доступа к статистике
  stats auth admin:admin@123
# Frontend является первой точкой входа для входящего трафика в HAProxy. Он слушает на определенных портах и принимает запросы от клиентов. 
# Когда клиент отправляет запрос на порт 8080, HAProxy будет прослушивать этот порт на всех доступных IP-адресах и обрабатывать входящие запросы, чтобы распределить их между соответствующими backend-серверами в соответствии с правилами балансировки нагрузки, заданными в конфигурации.
# HAProxy будет принимать HTTP-запросы от клиентов на настроенном порту и далее перенаправлять их на backend-сервер "prom", который был определен в этой же конфигурации.
frontend prom
  # Прослушивание всех доступных IP-адресов на порту 8080
  bind *:8080
  use_backend prom
backend prom
  server prom1 prometheus-1.basov.world:9090 check
  # Опция "backup" указывает, что этот сервер будет использоваться только в случае недоступности первого сервера (prom1).
  server prom2 prometheus-2.basov.world:9090 check backup
```
Данная конфигурация позволяет проксировать запросы c 8080 порта на один из Prom серверов.

Настройка Grafana.
3.1 Добавляем новый data source.
Добавление data source производится аналогично тому, как мы это делали в предыдущей
главе, за исключением адреса сервера. В качестве URL указываем: http://localhost:8080. В
качестве Name указываем: Prometheus HA.

Добавляем dashboard
https://grafana.com/grafana/dashboards/1860

Проверка результатов работы.
Для проверки необходимо выключить Prometheus поочередно на server1 и server2 и
убедиться, что графики продолжают отображаться:
systemctl stop prometheus.service

## Federation
Настраиваем чтобы основной prometheus server собирал информацию с других prometheus серверов


## Хранение данных на удаленных хранилищах. Настройка Remote read/write

Поддерживаемые удаленные хранилища:
AppOptics​: write
Azure Data Explorer​: read and write
Chronix​: write
Cortex​: read and write
CrateDB​: read and write
Elasticsearch​: write
Gnocchi​: write
Graphite​: write
InfluxDB​: read and write
IRONdb​: read and write
Kafka​: write
M3DB​: read and write
OpenTSDB​: write
PostgreSQL/TimescaleDB​: read and write
SignalFx​: write
Splunk​: read and write
TiKV​: read and write
Thanos​: write
VictoriaMetrics​: write
Wavefront​: write

см. слайд

## Thanos (настройка системы для долгосрочного хранения данных)

## API запросы
Коды ответа:
```
2xx – успешный запрос
400 – когда отсутствуют необходимые параметры или они не верные
422 – запрос не может быть выполнен
503 – время ожидания ответа превышено.
Метки времени могут быть переданы либо в формате https://www.ietf.org/rfc/rfc3339.txt, либо в формате Unix timestamp.
```

### Запросы мгновенного вектора
Ednpoint​: /api/v1/query

Method​: GET | POST

Параметры запроса:
- query – строка запроса PromQL.
- time – временная метка, за которую надо выбрать данные. Если параметр не задан, берется текущее время сервера.
- timeout – максимальное время выполнения запроса. Параметр не является обязательным. Если параметр не задан, используется значение query.timeout.

#### GET. Запрос up, время: 19.07.2023 09:10.51
```bash
curl 'http://localhost:9090/api/v1/query?query=up&time=2023-07-20T09:10:51.781Z'
```
Пример аналогичного запроса методом POST:
```bash
curl -XPOST -H 'Content-Type: application/x-www-form-urlencoded' -d "query=up" -d "time=2023-07-20T09:10:51.781Z" http://localhost:9090/api/v1/query
```

#### Запрос вектора за период времени
Ednpoint​: /api/v1/query_range

Method​: GET | POST

Параметры запроса:
query – строка запроса PromQL.
start – временная метка начала вектора.
end – временная метка окончания вектора.
step – шаг выборки данных; допустимый формат [0-9]+[smhdwy], например 5s, либо число float(секунды).
timeout – максимальное время выполнения запроса. Необязательный параметр. Если параметр не задан, используется значение query.timeout.

Пример.​ Запрос: up, за период с 19.07.2023 10:51.50 по 19.07.2023 10:15.51, с шагом в 30 секунд:
```bash
curl 'http://localhost:9090/api/v1/query_range?query=up&start=2023-07-19T09:10:51.781Z&end=2023-07-19T09:15:51.781Z&step=30s' > zapros
```
